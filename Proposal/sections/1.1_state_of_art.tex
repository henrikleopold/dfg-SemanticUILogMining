 
\subsubsection{State of the art} 
 
The problem we address in this proposal relates to three main research streams: 1) process mining, 2) robotic process automation, and 3) natural language processing in process analysis. Below, we briefly review each stream and highlight which gaps exist with respect to the four challenges we identified above.  

\textbf{Process mining} - Process mining is a family of data analysis techniques that facilitate the discovery, analysis, and improvement of organizational processes \cite{van2016data}. The core idea of process mining techniques is to analyze so-called \textit{event logs}. These event logs are extracted from information systems that support the execution of organizational processes and, therefore, capture how these processes are actually executed. In this proposal, we focus on \textit{process discovery}. Available process discovery techniques (see e.g. \cite{gunther2007fuzzy,weijters2011flexible,leemans2013discovering}) aim to provide the user with a visual representation of the process captured in the event log. Most of them generate process models, such as Petri Nets or Business Process Model and Notation (BPMN) models. Among others, this allows users to investigate the process flow and detect undesired patterns or sources of inefficiency that have so far been hidden in the event log. With respect to the challenges identified above, traditional process discovery relates to all five challenges: 

\textit{Noise filtering (challenge 1).} The removal of noise directly affects the quality of the process models generated by process discovery techniques. While first discovery techniques were not able to handle noise at all \cite{van2004workflow}, more recent discovery techniques take noise into account explicitly (e.g. \cite{weijters2003rediscovering,leemans2013discovering,van2016avoiding}). What is more, there are specific techniques available for removing noise from events logs before discovery techniques are applied \cite{tax2017discovering,CHENG2015138}. However, one of the key assumptions of all these techniques is that noise is highly infrequent. If certain behavior (such as visiting social media web sites) is observed on a regular basis, this unrelated behavior would be considered relevant part of the process execution. 

\textit{Case identification (challenge 2).}  The identification of cases is primarily addressed in the event log preparation phase since process discovery algorithms strictly require the availability of a case identifier. In literature, this problem of case identification is often also referred to as \textit{event correlation} \cite{diba2020extraction}. While there are several techniques for event correlation available, they consider rather restrictive settings. The technique from Ferreira and Gillblad  \cite{ferreira2009discovering} provide a solution for processes that do not contain loops or activity repetitions. The technique from Bayomie et al. \cite{bayomie2019probabilistic} assumes that a process model is already available. Both are assumptions that will not be met in the context of process discovery from UI logs. 

\textit{Event abstraction (challenge 3).} The issue of event abstraction has also been discussed in the context of traditional process discovery \cite{van2020event,diba2020extraction}. Since the level of granularity may also differ for back-end events, several abstraction techniques have been proposed to obtain a consistent and useful process model (e.g. \cite{baier2014bridging,van2020event,de2020event}). Available techniques differ with respect to many aspects such as the type of supervision (supervised/ unsupervised), the handling of concurrency (yes/ no), and the type of output (probabilistic/ deterministic). What is currently still missing from the perspective of this project is an unsupervised technique that can can deal with the large degree of variability in UI logs and reliably recognize respective higher level events. 

\textit{Event labeling (challenge 4).} Currently, there is also no technique available for automatically \textit{labeling} higher-level events. While the problem is generally recognized and discussed \cite{van2020event,van2016enabling}, the  solution is to delegate this task to domain experts. For a fully automated discovery technique, this strategy must be considered insufficient.   

\textit{Model discovery (challenge 5).} In principle, each of the available process model discovery techniques could be used to address the model discovery challenge of this proposal. However, existing discovery techniques were designed for traditional event logs and not for UI logs. Therefore, it is unclear which algorithm is best suited for this setting.  
 
 \noindent\fbox{%
\parbox{0.985\textwidth}{%
In summary, traditional process mining research has recognized the five challenges we identified for this project. Available solutions, however, are not applicable because of a limited scope, simplifying assumptions, or an insufficient degree of automation.
}}

\textbf{Robotic process automation} - Robotic process automation (RPA) is a technology that aims to automate repetitive human work. The core idea is to let so-called software robots (or bots) mimic the actions of a human directly in the GUI \cite{SYED2020103162}. One of the key challenges of RPA is to actually identify automatable tasks.  Recognizing this, the research domain of robotic process mining (RPM) has emerged in recent years \cite{leno2021robotic}. The goal of RPM techniques is to automatically identify automatable routines based on UI logs. By doing so, RPM techniques face a number of challenges that partially overlap with the five challenges we identified for this project. Specifically, RPM literature relates to challenges 1 and 2:   

\textit{Noise filtering (challenge 1).} The removal of noise  must be a considered a general pre-condition for the identification of automatable tasks. Apparently, activities such as social media visits or online shopping are neither part of a business-related task nor should the be automated in the context of RPA. However, fully automated solutions for noise removal from UI logs are missing. While noise removal techniques from traditional process mining (see \cite{tax2017discovering,CHENG2015138}) are generally applicable, their limitations for removing noise from UI logs have also been recognized \cite{leno2021robotic}. As a solution, some authors propose supervised noise removal based on an existing process model \cite{agostinelli202111} or they suggest using rules \cite{bosco2019discovering,leno2020identifying}. 

\textit{Case identification (challenge 2).} The identification of cases in RPM conceptually differs from case identification in traditional process mining. The underlying assumption is that the cases do not overlap and, thus, the case identification can be achieved by splitting the log into segments. To achieve this so-called segmentation task, researchers have proposed manually, supervised, and unsupervised approaches. Urabe et al. \cite{urabe2019visualizing} introduced a manual approach that visualizes the UI log using a graph and, in this way, supports the user in identifying segment boundaries. Agostinelli et al. \cite{agostinelli202111} proposed a supervised approach that leverages trace alignments from conformance checking. This approach, however, requires a Petri net representing the underlying process as input. An unsupervised approach was introduced by Leno et al. \cite{leno2020identifying}. They construct a control-flow graph from the UI log and use back edges detection to identify segment boundaries. Another, very recent, unsupervised approach from Urabe et al. \cite{Urabe21} leverages the concept of co-occurrence from topic segmentation in natural language processing to segment the UI log. Despite the effectiveness of these techniques, they all share the assumption that cases are conducted strictly sequentially. Therefore, these techniques are not sufficient to address challenge 2 from our project.   

\noindent\fbox{%
\parbox{0.985\textwidth}{%
In summary, robotic process automation techniques have proposed first solutions for noise filtering (challenge 1) and case identification (challenge 2) in UI logs. However, these solutions are either supervised or they assume that the cases in the UI log are non-overlapping. 
}}

\textbf{Natural language processing in process analysis} - A wide range of techniques for process analysis build on natural language processing (NLP). They can be subdivided into three main categories: 1) techniques that apply NLP to process models, 2) techniques that apply NLP to process-related text documents, and 3) techniques that apply NLP to event logs. Techniques that apply NLP to \textit{process models} typically analyze the text labels of activities, events, and gateways. Among others, this facilitates the detection and correction of inconsistent terminology \cite{koschmider2007user,pittke2015automatic} and violations of labeling conventions \cite{becker2009towards,leopold2013detection}. Techniques that apply NLP to \textit{process-related text documents} are mainly concerned with process model elicitation. There is a wide range of techniques available for eliciting process models from general purpose process descriptions \cite{ghose2007process,friedrich2011process,epure2015automatic} and more specific textual resources such as use cases \cite{sinha2010use} or group stories  \cite{de2009business}. In recent literature, there are also more and more techniques that apply NLP to \textit{event logs}. One key concern addressed by these techniques is the quality of event logs. There are techniques for automatically relabeling unsuitable event text labels \cite{ramos2021nlp} as well as for automatically aggregating events in order to obtain a more appropriate level of granularity \cite{deokar2015semantics}. With respect to the challenges of this proposal, existing techniques NLP for process analysis provide relevant input for challenges 1, 3, and 4: 

\textit{Noise filtering (challenge 1).} So far, the removal of noise in event or UI logs has not been explicitly approached from an NLP angle. However, in a recent contribution, we defined an approach to extract semantic process information, such as actions, objects, and roles, from text labels in event logs \cite{rebmann2021extracting}. In \cite{van2021natural}, we also showed that this approach can be leveraged to identify semantic execution anomalies in event logs. We consider both approaches an important basis for filtering noise: The former to extract and analyze text from element labels and element values; the latter to recognize whether the extracted text components indicate a noisy event. However, given the scope on semantic execution anomalies, this perspective is not sufficient to recognize all types of noise. Particularly, the recognition of non-business related events requires novel semantic techniques.   
 
 \textit{Event abstraction (challenge 3).} While there are many works that are concerned with event abstraction in the context of process mining, only a very few techniques leverage NLP. The most notable one is the technique for event aggregation from Deokar and Tao \cite{deokar2015semantics}. They, however, rely on the taxonomy WordNet \cite{miller1995wordnet}, which has proven to be quite limited in the context of process analytics due to its rather narrow scope \cite{leopold2015towards}. Given the specific process contexts we expect to encounter, we therefore need to define an abstraction technique that builds on other resources. 
   
\textit{Event labeling (challenge 4).}  The challenge of labeling events that result from event abstraction in event logs is conceptually highly similar to labeling activities that result from activity abstraction in process models. In prior work, we defined a technique that attempts to automatically determine names for (to be aggregated) process model fragments \cite{leopold2014simplifying}. The technique, however, relies on the specifics of event-driven process chains (EPCs) and, therefore, cannot be transferred to labeling higher-level events. 

 \noindent\fbox{%
\parbox{0.985\textwidth}{%
In summary, NLP plays important role in the context of automated process analysis. Existing techniques leveraging NLP for process model and event log analysis provide relevant starting points to address challenges 1, 3, and 4. However, they are not suitable to effectively address these challenges.
}}

\subsubsection{Preliminary work}

\todo{Reactivate this part. Basically bragging.}
%%%%%%%% THIS IS FROM THE "PRELIMANRY WORK" SECTION FROM MY OLD PROPOSAL

%Currently, Prof. Leopold is a tenured Associate Professor at the KÃ¼hne Logistics University and a senior researcher at the Hasso Plattner Institute at the University of Potsdam. He has published over 60 peer-reviewed contributions, among others, in renowned journals such as IEEE Transactions on Knowledge and Data Engineering, IEEE Transactions on Software Engineering, Information Systems, and Decision Support Systems, as well as at leading international conferences, such as Business Process Management (BPM), Advanced Information Systems Engineering (CAiSE), and Computational Linguistics (COLING). These works relate to various aspects of the proposed project, as outlined below in terms of natural language processing in process analysis and process model matching.

%\textbf{Natural language processing in process analysis} - Prof. Leopold has been involved in the development of various techniques that combine natural language processing and process analysis. Among others, he has developed parsers for process model labels \cite{leopold2012refactoring,leopold2019using} that facilitate the automated semantic analysis of process models. Building on these parsers, he further developed techniques for the generation of natural language texts from process models \cite{leopoldsupporting2014} and the automated identification of service candidates from process model repositories \cite{leopold2015_jss}. More recently, Prof. Leopold has been involved in the development of several techniques analyzing textual process descriptions. Among others, he contributed to a technique that can extract process performance indicators from textual process descriptions \cite{van2017transforming} and a technique that can detect to what extent the process behavior described by a textual process description deviates from an event log \cite{vanderaa2018checking}. 

%\textbf{Process model matching} - Prof. Leopold contributed to the development of a variety of process model matching techniques. Among others, he was involved in developing different techniques for matching two process models \cite{leopold2012probabilistic,van2017instance,meilicke2017overcoming}, process models and textual process descriptions \cite{vanderaa2016comparing}, and process models and taxonomies \cite{leopold2015towards}. Besides developing novel process matching techniques, he also contributed to the discourse on process matching evaluation \cite{kuss2018probabilistic}.

%In the proposed project, we will build on our prior work in different ways. On the one hand, we will reuse specific techniques, such as the parsing technique from \cite{leopold2019using} for analyzing event labels (see Section \ref{sec:wp2}). On the other hand, we will build on the experiences we gained in related settings. The experience we collected in \cite{van2017transforming} with respect to sentence classification will help us to detect and classify process weaknesses (see Section \ref{sec:wp1}). The experience with distributional semantics in \cite{leopold2015towards} will help us to define effective mechanisms to identify how posts and events are related (see Section \ref{sec:wp2}). Lastly, the experience with respect to matching, and Markov Logic formalizations in particular, will help us to address the problem of aligning a non-process-oriented and a process-oriented data structure (see Section \ref{sec:wp3}).  
